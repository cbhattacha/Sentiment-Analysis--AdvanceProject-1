{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn, sentiwordnet as swn\n",
    "from token_embeddings import generate_embeddings\n",
    "from tokenize_clean_text import clean_text\n",
    "\n",
    "# Instantiate the WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate embeddings for our corpus, makes a file project_embeddings.csv and stores it in directory\n",
    "generate_embeddings(\"only_tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.read_csv(\"project_embeddings.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering\n",
    "\n",
    "def cluster_embeddings(df, num_of_clusters):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = num_of_clusters, random_state=42).fit(df)\n",
    "    group_num = kmeans.labels_\n",
    "    geo_centroids = kmeans.cluster_centers_\n",
    "    \n",
    "    #assign nearest word to geometric centroid in embedding space as centroid\n",
    "    # find the index of the closest points from x to each class centroid\n",
    "    close = pairwise_distances_argmin_min(geo_centroids, df, metric='euclidean')\n",
    "    index_closest_points = close[0]\n",
    "    word_centroids = df.iloc[index_closest_points].index\n",
    "    \n",
    "    #create dict of group number and centroids\n",
    "    centroid_dict = {}\n",
    "    for i in range(len(index_closest_points)):\n",
    "        centroid_dict[i] = word_centroids[i]\n",
    "    \n",
    "    #create a dictionary of word and corresponding centroid\n",
    "    \n",
    "    #replace each label(group number) assigned by kmeans cluster algo with centroid word\n",
    "    cen = [centroid_dict.get(group) for group in group_num]\n",
    "\n",
    "    #create a dictionary\n",
    "    word_centroid_dict = {}\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        word_centroid_dict[df.index[i]] = cen[i]\n",
    "    \n",
    "    return word_centroid_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace words in reviews with their cluster centroids and then calculate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_centroids(review, word_centroid_dict):\n",
    "    \n",
    "    new_review = [word_centroid_dict.get(word) if word in word_centroid_dict else word for word in review]\n",
    "    \n",
    "    return new_review    \n",
    "    \n",
    "    \n",
    "\n",
    "def swn_classifier(review):\n",
    " \n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0.0\n",
    "    \n",
    "    #Calculating score\n",
    "    for word in review:\n",
    "        \n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "        if not lemma:\n",
    "            continue\n",
    " \n",
    "        synsets = wn.synsets(lemma)\n",
    "        if not synsets:\n",
    "            continue\n",
    "        \n",
    "        # Take the first synset, the most common\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        print()\n",
    " \n",
    "        #sentiment is the difference between positive and negative score\n",
    "        sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        tokens_count += 1\n",
    " \n",
    "    # Default: neither positive, nor negative\n",
    "    if not tokens_count:\n",
    "        return 0\n",
    " \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the cluster function to generate a word centroid dictionary. Num is a hyperparameter to be adjusted for best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the cluster function to generate a word centroid dictionary\n",
    "num = 2000   #roughly 11 words per cluster\n",
    "word_centroid_dict = cluster_embeddings(embeddings_df, num)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data file, process it(sentiment classification) and export it in required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import reviews file\n",
    "#use both review title and review content columns to predict score\n",
    "reviews = pd.read_csv(\"only_tweet.csv\")\n",
    "\n",
    "#arrays to store list of tokens, replaced words, scores\n",
    "clean_tokens = []\n",
    "replaced_tokens = []\n",
    "y_predicted = []\n",
    "\n",
    "\n",
    "#calling the main calculate function\n",
    "for review in reviews[\"text\"]:    \n",
    "    clean_t = clean_text(review)\n",
    "    clean_tokens.append(clean_t)\n",
    "    \n",
    "    replaced_t = replace_with_centroids(clean_t, word_centroid_dict)\n",
    "    replaced_tokens.append(replaced_t)\n",
    "    \n",
    "    senti_score = swn_classifier(replaced_t)\n",
    "    y_predicted.append(senti_score)\n",
    "\n",
    "    \n",
    "#Classify reviews according to setiment score assigned\n",
    "#1 : positive, 0 : neutral, -1 : negative \n",
    "y_classified = []\n",
    "for i in y_predicted:\n",
    "    if i > 0:\n",
    "        y_classified.append(1)\n",
    "    elif i<0:\n",
    "        y_classified.append(-1)\n",
    "    elif i==0:\n",
    "        y_classified.append(0)\n",
    "        \n",
    "\n",
    "#appending cols in df\n",
    "reviews[\"tokens\"] = clean_tokens\n",
    "reviews[\"replaced_centroids\"] = replaced_tokens\n",
    "reviews[\"sentiment_score\"] = y_predicted\n",
    "reviews[\"predicted_sentiment\"] = y_classified\n",
    "\n",
    "#exporting df\n",
    "reviews.to_csv(\"classified_full_review_embeddings.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(\"op_embeddings_score.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_word_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(reviews[\"true_sentiment\"], y_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(reviews[\"true_sentiment\"], y_classified, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some examples:\n",
    "for n in range(0,100,20):\n",
    "    print(\"user_rating:\",reviews[\"rating\"][n] )\n",
    "    print(\"review:\",reviews[\"full_review\"][n])\n",
    "    print(\"tokens:\",reviews[\"tokens\"][n])\n",
    "    print(\"replaced centroids:\",reviews[\"replaced_centroids\"][n])\n",
    "    print(\"sentiment_score:\",reviews[\"sentiment_score\"][n],'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
